# General params
batch_size: 2

learning_rate: 0.0000005
epochs: 500
seq_len: 15

clip_len: 1
frame_len: 1

# Optimisation
dropout: 0.7
momentum: 0.005
weight_decay: 0.05
scheduling: True
warm_up: 2
n_classes: 15

# num_samples: 50000
# Architecure optimisation

input_dimension: 2048
nhead: 8
token_embedding: 305
nlayers: 8
nhid: 2048
projection_size: 305

data_set: "mmx-frame"

# double_transformer, single_transformer, lstm, frame_transformer

model: "frame_transformer"
logger: "double_transformer"
name: "mmx-frame-test"

#experts: ["test-video-embeddings", "test-location-embeddings", "test-img-embeddings", "audio-embeddings"]
experts: ["img-embeddings", "location-embeddings", "video-embeddings"]
# experts: ["location-embeddings", "img-embeddings", "video-embeddings", "audio-embeddings"]
# pool or None
cls: 1

# Multi modal settings
mixing_method: "double_trans"

device: 1
save_path: "/trained_models/mit/transformer/"
