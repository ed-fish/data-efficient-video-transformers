# General params
batch_size: 3
learning_rate: 0.0000005
epochs: 500
seq_len: 23
test: True

clip_len: 1
frame_len: 1

# Optimisation
dropout: 0.6
momentum: 0.005
weight_decay: 0.09
scheduling: True
warm_up: 2
n_classes: 15
opt: "adamW"

# num_samples: 50000
# Architecure optimisation

input_dimension: 2048
nhead: 8
token_embedding: 305
nlayers: 8
nhid: 2048
projection_size: 305

data_set: "mmx-frame"

# double_transformer, single_transformer, lstm, frame_transformer, sum, frame, vid, pre_modal, sum_residual

model: "sum_residual"
logger: "double_transformer"
name: "mmx-frame-test"

#experts: ["test-video-embeddings", "test-location-embeddings", "test-img-embeddings", "audio-embeddings"]
experts: ["img-embeddings", "location-embeddings", "video-embeddings"]
# experts: ["location-embeddings", "img-embeddings", "video-embeddings", "audio-embeddings"]
# pool or None
cls: 1

# Multi modal settings
mixing_method: "double_trans"

device: 1
save_path: "/trained_models/mit/transformer/"
