# General params
batch_size: 10
learning_rate: 0.000001
epochs: 500
seq_len: 35
clip_len: 1
frame_len: 1

# Optimisation
dropout: 0.5
momentum: 0.9
weight_decay: 0.00005
scheduling: True
warm_up: 2
n_classes: 15

# num_samples: 50000
# Architecure optimisation

input_dimension: 2048
nhead: 2
token_embedding: 305
nlayers: 4
nhid: 1028
projection_size: 305

data_set: "mmx-frame"
# double_transformer, single_transformer, lstm
model: "frame_transformer"
logger: "double_transformer"
name: "mmx-frame-test"

#experts: ["test-video-embeddings", "test-location-embeddings", "test-img-embeddings", "audio-embeddings"]
experts: ["img-embeddings", "location-embeddings", "video-embeddings"]
# experts: ["location-embeddings", "img-embeddings", "video-embeddings", "audio-embeddings"]
# pool or None
cls: 1

# Multi modal settings
mixing_method: "double_trans"

device: 1
save_path: "/trained_models/mit/transformer/"
