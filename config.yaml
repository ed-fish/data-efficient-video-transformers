---
batch_size: 2
train_csv:  /home/ed/PhD/mmodal-moments-in-time/example.csv
train_root: /home/ed/PhD/Embeddingator/output/training/
val_root: /home/ed/PhD/Embeddingator/output/validation/

# which expert to use, image, motion, location, depth
experts: ["motion", "image", "location"]
learning_rate: 0.005
epochs: 10

expert_dim_size: 1028
input_shape: 4608
output_shape: 128
bottle_neck: 512
device: 0
# number of layers to train with
num_layers: 2 
data_size: 100
# Method for pooling img, depth, and location embeddings. 
# avg, max, random (select a random frame each time)
aggregation: "concat"

multi_crop_temporal: False

resume: False
resume_path: ""
noise_multiplier: 10

# Flip is the probability an image will be flipp
flip: 0.5

# Jitter val is random augmentation between 0, 2
jitter: 50

# Grey is probability the img will be converted
gray: 0.2 # gray used rather than grey for consi

# Noise is the probability that the noise multip
noise: 0.3

# Location of csv file output
csv: "/database.csv"

# Number of frames to skip : used as if frames %
frames: 2
frame_length: 16
tidy_start: 0

# Normalisation for multi modes

# Resnet
image_norm:
        mean: [0.485, 0.456, 0.406]
        std: [0.229, 0.224, 0.225]

depth_norm:
        mean: [0.485, 0.456, 0.406]
        std: [0.229, 0.224, 0.225]

# Resnet 3D 18 - kinetics 400 - clipp acc@5 75.4
video_norm:
        mean: [0.43216, 0.394666, 0.37645]
        std: [0.22803, 0.22145, 0.216989]

location_norm:
        mean: [0.485, 0.456, 0.406]
        std: [0.229, 0.224, 0.225]

# Which GPU to use (for parallel use 0)
gpu: 0
