--- 
# General params
batch_size: 10
learning_rate: 0.005
epochs: 500
seq_len: 200

# Optimisation
dropout: 0.5
momentum: 0.0005
weight_decay: 0.00005
scheduling: True
warm_up: 2

# num_samples: 50000
# Architecure optimisation

input_shape: 2048
token_embedding: 1024
hidden_layer: 2048
projection_size: 512
output_shape: 128
gpu: 3

# total, max, avg
pooling: "none"

# Data input
# img = 2048, location = 2048, motion = 512, audio = 128, all=4736

experts: ["test-video-embeddings", "test-location-embeddings", "test-img-embeddings", "audio-embeddings"]
train_experts: ["img-embeddings"]
test_experts: ["test-img-embeddings"]
# experts: ["location-embeddings", "img-embeddings", "video-embeddings", "audio-embeddings"]
n_labels: 15
n_heads: 4
# pool or None
frame_agg: "none"
frame_id: 0

# Multi modal settings
mixing_method: "post_collab"
cat_norm: False
cat_softmax: False

# options = "pre-trans", "post-trans", "pre_contrast"
architecture: "post-trans"

# Self supervised options
device: 3
# Method for pooling img, depth, and location embeddings.1
# avg, max, random (select a random frame each time)
aggregation: "none"

save_path: "/trained_models/mmx/transformer/"
