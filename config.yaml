--- 
# General params
batch_size: 10
learning_rate: 0.003
epochs: 500
seq_len: 200

# Optimisation
dropout: 0.7
momentum: 0.0005
weight_decay: 0.0005
scheduling: True
warm_up: 2
#num_samples: 50000

# Architecure optimisation

input_shape: 4736
token_embedding: 15
hidden_layer: 1024
projection_size: 512
output_shape: 128
gpu: 2

# total, max, avg
pooling: "none"

# Data input
# img = 2048, location = 2048, motion = 512, audio = 128
experts: ["test-img-embeddings", "test-location-embeddings", "test-video-embeddings", "audio-embeddings"]
train_experts: ["img-embeddings"]
test_experts: ["test-img-embeddings"]
# experts: ["location-embeddings", "img-embeddings", "video-embeddings", "audio-embeddings"]
n_labels: 15
n_heads: 4
# pool or None
frame_agg: "none"
frame_id: 0

# Multi modal settings
mixing_method: "concat"
cat_norm: False
cat_softmax: False

# options = "pre-trans", "post-trans", "pre_contrast"
architecture: "pre-contrast"

# Self supervised options
device: 2
# Method for pooling img, depth, and location embeddings.1
# avg, max, random (select a random frame each time)
aggregation: "none"
