# General params
batch_size: 64
learning_rate: 0.000001
epochs: 500
seq_len: 3

# Optimisation
dropout: 0.5
momentum: 0.9
weight_decay: 0.0005
scheduling: True
warm_up: 2
n_classes: 305

# num_samples: 50000
# Architecure optimisation

input_shape: 512
input_dimension: 2048
ninp: 2048
nhead: 2
token_embedding: 1024
ntoken: 305
hidden_layer: 2048
mixing: "post-collab"
encoder_layers: 2048
nlayers: 2
nhid: 1850
projection_size: 304
output_shape: 128
gpu: 2 

# total, max, avg
pooling: "none"

# Data input
# img = 2048, location = 2048, motion = 512, audio = 128, all=4736

#experts: ["test-video-embeddings", "test-location-embeddings", "test-img-embeddings", "audio-embeddings"]
experts: ["test-video-embeddings"]
train_experts: ["img-embeddings"]
test_experts: ["test-img-embeddings"]
# experts: ["location-embeddings", "img-embeddings", "video-embeddings", "audio-embeddings"]
n_labels: 15
n_heads: 2
# pool or None
frame_agg: "none"
frame_id: 0
cls: 0

# Multi modal settings
mixing_method: "post_collab"
mixing: "post_collab"
cat_norm: False
cat_softmax: False

# options = "pre-trans", "post-trans", "pre_contrast"
architecture: "post-trans"

# Self supervised options
device: 2
# Method for pooling img, depth, and location embeddings.1
# avg, max, random (select a random frame each time)
aggregation: "none"
save_path: "/trained_models/mmx/transformer/"
